{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "from mpl_toolkits import mplot3d\n",
    "import random\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score\n",
    "from sklearn import preprocessing\n",
    "import math\n",
    "from scipy.spatial.distance import euclidean as eu\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1.axes_divider import make_axes_locatable\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "import Data_load as dl\n",
    "from scipy import signal\n",
    "from scipy.fftpack import fft, dct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intuition\n",
    "The main problem we need to tackle is the variable lengths of the data. Other approaches involve extraction of a fixed number of features (n), which leads to the same n-dimensional dataset with each dimension representing a feature. This needs a keen understanding of the domain, and still considers many assumptions about the features to be selected. In case of incomplete knowledge of the domain, the feature selection process may miss out on crucial aspects of the signal.\n",
    "If we were to consider the raw signal for processing, then the process of equalising the lengths includes padding or interpolating data. However, adding information to temporal data can change the significance of the temporal and spectral properties of the signal.\n",
    "\n",
    "## Frequency Domain\n",
    "A frequency transform of the time series data is computed, which in most cases, preserves the important information present in the data set. However, the length of the signals differ in the spectral domain as well. We can now make changes to the signal in the frequency domain without changing temporal properties of the signal. To avoid adding points to the signal, we can consider a sliding window over the signal and create groups or bins of frequencies. If we make the same number of bins across the signal, while keeping a fraction of frequencies common between adjacent bins, we can capture defining aspects of the temporal domain without making decisions to include or exclude specific features. With the same number of bins for each signal the final output will be of the same length and can be considered unadulterated data which is compressed to a specific spectral group.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Collecting the data into Dyslexic and Control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_list=['LX', 'LY', 'RX', 'RY']\n",
    "C_data, D_data = dl.get_data()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "new_vals() - takes the eye tracking readings from the left and right eye and combines it into a single array of complex numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_vals(data):\n",
    "    x = [sum(x) for x in zip(data['LX'].to_list(), data['RX'].tolist())]\n",
    "    y = [sum(x) for x in zip(data['LY'].to_list(), data['RY'].tolist())]\n",
    "    \n",
    "    compl = np.array([complex(a,b) for a,b in zip(x, y)])\n",
    "    \n",
    "    return compl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "binning() - maps a vector any lenght to a vector of a fixed length(bins) as needed.  This helps to compare vectors of various lengths. Each entry of the resulting vector is a sum of fixed number of elements of the input vector. Few of these elements are considered common for successive entries into the resulting vector. This is the overlapping factor. \n",
    "\n",
    "\n",
    "So the fixed number of elements considered for the each entry = (lenght of input vector/lenght of output vector) + overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binning(bins, fft, overlap_per):\n",
    "    div_size = len(fft)/bins\n",
    "    bin_size = div_size*(1+(overlap_per/100))\n",
    "    half_bin = bin_size/2\n",
    "    \n",
    "    binned = []\n",
    "    \n",
    "    current_step = bin_size\n",
    "    for a in range(bins):\n",
    "        \n",
    "        pos = np.ceil(half_bin + a*(div_size))\n",
    "        start = 0 if a == 0 else int(np.ceil(pos - half_bin))\n",
    "        end = -1 if a == (bins-1) else int(np.ceil(pos + half_bin))\n",
    "        #print([start, end])\n",
    "        \n",
    "        binned = np.append(binned, sum(np.abs(fft[start : end]))) \n",
    "        \n",
    "    return binned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "kmeans_binning() - kmeans clustering of the binned vectors. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kmeans_binning(D_data,C_data, bins, bins_per):\n",
    "    \n",
    "    data_sets = [D_data,C_data]\n",
    "    all_buckets = []\n",
    "    for dataset in data_sets:\n",
    "        for no in range(len(dataset)):\n",
    "            d = new_vals(dataset[no])\n",
    "            fft = dct(d)   \n",
    "\n",
    "            binned = binning(bins, fft, bins_per)\n",
    "            all_buckets.append(binned)\n",
    "            buckets = np.asarray(all_buckets)\n",
    "            \n",
    "    kmeans = KMeans(n_clusters = 2, random_state=0).fit(buckets)\n",
    "    predicted_labels = kmeans.labels_\n",
    "    actual_labels = np.concatenate((np.ones(98), np.zeros(88)))\n",
    "    \n",
    "    conf_m = confusion_matrix(actual_labels,predicted_labels)[:2]\n",
    "    acc = accuracy_score(actual_labels,predicted_labels)*100\n",
    "    \n",
    "    return buckets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec = kmeans_binning(D_data,C_data, 1000, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.asarray(vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "y= np.concatenate((np.ones(88), np.zeros(98)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "vals1 = np.load('accuracy_vals.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Perceptron\n",
    "clf = Perceptron(tol=1e-3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Perceptron(alpha=0.0001, class_weight=None, early_stopping=False, eta0=1.0,\n",
       "           fit_intercept=True, max_iter=1000, n_iter_no_change=5, n_jobs=None,\n",
       "           penalty=None, random_state=0, shuffle=True, tol=0.001,\n",
       "           validation_fraction=0.1, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7258064516129032"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X, y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
